{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8cDtxLIBHgQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c464d37-a540-4b28-9999-328de66aff5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Oct 26 01:23:56 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdSMcABDNKW-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bf27660-29c6-48ba-dda6-66dd68927c1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "# Pip install method (recommended)\n",
        "\n",
        "!pip install ultralytics\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/runs/detect/train/args.yaml\n",
        "task: detect\n",
        "mode: train\n",
        "model: yolov8m.pt\n",
        "data: /content/Scatch-6/data.yaml\n",
        "epochs: 300\n",
        "time: null\n",
        "patience: 100\n",
        "batch: 64\n",
        "imgsz: 640\n",
        "save: true\n",
        "save_period: -1\n",
        "cache: false\n",
        "device: null\n",
        "workers: 8\n",
        "project: null\n",
        "name: train5\n",
        "exist_ok: false\n",
        "pretrained: true\n",
        "optimizer: auto\n",
        "verbose: true\n",
        "seed: 0\n",
        "deterministic: true\n",
        "single_cls: false\n",
        "rect: false\n",
        "cos_lr: false\n",
        "close_mosaic: 10\n",
        "resume: false\n",
        "amp: true\n",
        "fraction: 1.0\n",
        "profile: false\n",
        "freeze: null\n",
        "multi_scale: false\n",
        "overlap_mask: true\n",
        "mask_ratio: 2\n",
        "dropout: 0.0\n",
        "val: true\n",
        "split: val\n",
        "save_json: false\n",
        "save_hybrid: false\n",
        "conf: null\n",
        "iou: 0.7\n",
        "max_det: 100\n",
        "half: false\n",
        "dnn: false\n",
        "plots: true\n",
        "source: null\n",
        "vid_stride: 1\n",
        "stream_buffer: false\n",
        "visualize: false\n",
        "augment: false\n",
        "agnostic_nms: false\n",
        "classes: null\n",
        "retina_masks: false\n",
        "embed: null\n",
        "show: false\n",
        "save_frames: false\n",
        "save_txt: false\n",
        "save_conf: false\n",
        "save_crop: false\n",
        "show_labels: true\n",
        "show_conf: true\n",
        "show_boxes: true\n",
        "line_width: null\n",
        "format: torchscript\n",
        "keras: false\n",
        "optimize: false\n",
        "int8: false\n",
        "dynamic: false\n",
        "simplify: false\n",
        "opset: null\n",
        "workspace: 4\n",
        "nms: false\n",
        "lr0: 0.005\n",
        "lrf: 0.005\n",
        "momentum: 0.937\n",
        "weight_decay: 0.0005\n",
        "warmup_epochs: 5.0\n",
        "warmup_momentum: 0.6\n",
        "warmup_bias_lr: 0.05\n",
        "box: 7.5\n",
        "cls: 0.5\n",
        "dfl: 1.5\n",
        "pose: 12.0\n",
        "kobj: 1.0\n",
        "label_smoothing: 0.0\n",
        "nbs: 64\n",
        "hsv_h: 0.000\n",
        "hsv_s: 0.0\n",
        "hsv_v: 0.0\n",
        "degrees: 0.0\n",
        "translate: 0.0\n",
        "scale: 0.0\n",
        "shear: 0.0\n",
        "perspective: 0.0\n",
        "flipud: 0.0\n",
        "fliplr: 0.0\n",
        "bgr: 0.0\n",
        "mosaic: 0.0\n",
        "mixup: 0.0\n",
        "copy_paste: 0.0\n",
        "auto_augment: randaugment\n",
        "erasing: 0.4\n",
        "crop_fraction: 1.0\n",
        "cfg: null\n",
        "tracker: botsort.yaml\n",
        "save_dir: runs/detect/train5\n"
      ],
      "metadata": {
        "id": "rx0PZ4Tpm72h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the model\n",
        "model = YOLO('yolov8m.yaml')\n",
        "\n",
        "# Train the model with hyperparameters from the separate file\n",
        "model.train(\n",
        "    data='/content/Scatch-6/data.yaml',\n",
        "    epochs=300,\n",
        "    imgsz=640,\n",
        "    batch=32,\n",
        "    save=True,\n",
        "    save_period=-1,\n",
        "    cache=False,\n",
        "    device=None,\n",
        "    workers=8,\n",
        "    project=None,\n",
        "    name='train',\n",
        "    exist_ok=False,\n",
        "    pretrained=True,\n",
        "    optimizer='auto',\n",
        "    verbose=True,\n",
        "    seed=0,\n",
        "    deterministic=True,\n",
        "    single_cls=False,\n",
        "    rect=False,\n",
        "    cos_lr=False,\n",
        "    close_mosaic=10,\n",
        "    resume=False,\n",
        "    amp=True,\n",
        "    fraction=1.0,\n",
        "    profile=False,\n",
        "    freeze=None,\n",
        "    multi_scale=False,\n",
        "    overlap_mask=True,\n",
        "    mask_ratio=2,\n",
        "    dropout=0.0,\n",
        "    val=True,\n",
        "    split='val',\n",
        "    save_json=False,\n",
        "    save_hybrid=False,\n",
        "    conf=None,\n",
        "    iou=0.7,\n",
        "    max_det=100,\n",
        "    half=False,\n",
        "    dnn=False,\n",
        "    plots=True,\n",
        "    source=None,\n",
        "    vid_stride=1,\n",
        "    stream_buffer=False,\n",
        "    visualize=False,\n",
        "    augment=False,\n",
        "    agnostic_nms=False,\n",
        "    classes=None,\n",
        "    retina_masks=False,\n",
        "    embed=None,\n",
        "    show=False,\n",
        "    save_frames=False,\n",
        "    save_txt=False,\n",
        "    save_conf=False,\n",
        "    save_crop=False,\n",
        "    show_labels=True,\n",
        "    show_conf=True,\n",
        "    show_boxes=True,\n",
        "    line_width=None,\n",
        "    format='torchscript',\n",
        "    keras=False,\n",
        "    optimize=False,\n",
        "    int8=False,\n",
        "    dynamic=False,\n",
        "    simplify=False,\n",
        "    opset=None,\n",
        "    workspace=4,\n",
        "    nms=False,\n",
        "    lr0=0.005,\n",
        "    lrf=0.005,\n",
        "    momentum=0.937,\n",
        "    weight_decay=0.0005,\n",
        "    warmup_epochs=5.0,\n",
        "    warmup_momentum=0.6,\n",
        "    warmup_bias_lr=0.05,\n",
        "    box=7.0,\n",
        "    cls=0.5,\n",
        "    dfl=1.5,\n",
        "    pose=12.0,\n",
        "    kobj=1.0,\n",
        "    label_smoothing=0.0,\n",
        "    nbs=64,\n",
        "    hsv_h=0.000,\n",
        "    hsv_s=0.0,\n",
        "    hsv_v=0.0,\n",
        "    degrees=0.0,\n",
        "    translate=0.0,\n",
        "    scale=0.7,\n",
        "    shear=0.0,\n",
        "    perspective=0.0,\n",
        "    flipud=0.0,\n",
        "    fliplr=0.0,\n",
        "    bgr=0.0,\n",
        "    mosaic=0.0,\n",
        "    mixup=0.0,\n",
        "    copy_paste=0.5,\n",
        "    auto_augment='randaugment',\n",
        "    erasing=0.4,\n",
        "    crop_fraction=1.0,\n",
        "    cfg=None,\n",
        "    tracker='botsort.yaml',\n",
        "    save_dir='runs/detect/train5'\n",
        ")\n"
      ],
      "metadata": {
        "id": "DB-7K-3V7WLZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "325b1672-87f7-4ca9-f934-605a17ffad52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.84 ðŸš€ Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.yaml, data=/content/Scatch-6/data.yaml, epochs=300, time=None, patience=100, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train5, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=2, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=100, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.005, lrf=0.005, momentum=0.937, weight_decay=0.0005, warmup_epochs=5.0, warmup_momentum=0.6, warmup_bias_lr=0.05, box=7.0, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.7, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train5\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
            "YOLOv8m summary: 295 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train5', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Scatch-6/train/labels.cache... 340 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Scatch-6/valid/labels.cache... 84 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 84/84 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train5/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.005' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train5\u001b[0m\n",
            "Starting training for 300 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      1/300      13.1G      4.693      9.086      4.171         68        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:12<00:00,  1.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      2/300      14.2G      4.666      5.958      3.984         79        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:12<00:00,  1.14s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      3/300      14.2G      4.597      4.676      3.628         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:12<00:00,  1.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      4/300      14.2G      4.303      4.246      3.381         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      5/300      14.2G      4.161      3.993      3.141         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      6/300      13.8G      4.032      3.984      3.063         77        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407   0.000238    0.00491   0.000121   4.86e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      7/300      14.2G      4.034      3.786      2.991        106        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407   0.000238    0.00491   0.000121   4.86e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      8/300      13.8G      4.022       3.75       2.92         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407   0.000613    0.00246   0.000188   6.78e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      9/300      14.2G      3.984      3.678       2.88         99        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407   0.000714     0.0147   0.000382   8.12e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     10/300      13.8G      3.975      3.686       2.79         98        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407   0.000714     0.0147   0.000382   8.12e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     11/300      14.2G      3.962       3.64      2.847         79        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407    0.00578    0.00491    0.00114   0.000289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     12/300      13.9G      3.936      3.683      2.778         74        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407    0.00103    0.00246   0.000396   8.67e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     13/300      14.2G      3.859      3.651      2.688         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407   0.000149    0.00246   7.49e-05   2.25e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     14/300      13.8G       3.87      3.595      2.703         87        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407   0.000149    0.00246   7.49e-05   2.25e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     15/300      14.2G      3.897      3.633      2.739         90        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407   0.000238    0.00491    0.00012   3.59e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     16/300      13.8G      3.825      3.594      2.739         89        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407    0.00131      0.027   0.000673   0.000189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     17/300      14.2G      3.806      3.603      2.655         78        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:10<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407   0.000119    0.00246   5.98e-05   5.98e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     18/300      13.8G      3.832      3.612      2.684         86        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407   0.000952     0.0197   0.000486   0.000139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     19/300      14.2G      3.832      3.595      2.653         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407   0.000595     0.0123   0.000302   5.43e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     20/300      13.8G      3.867      3.565      2.624         87        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407    0.00131      0.027   0.000759   0.000162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     21/300      14.2G      3.733      3.621      2.604         70        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407    0.00108     0.0221   0.000571    0.00012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     22/300      13.8G      3.686      3.579      2.529         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407    0.00381     0.0147     0.0008   0.000198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     23/300      14.2G      3.703      3.613      2.574         73        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407   0.000357    0.00737    0.00018    3.6e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     24/300      13.8G      3.711      3.583       2.55         75        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407   0.000357    0.00737    0.00018    3.6e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     25/300      14.2G      3.676       3.54      2.493         90        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407   0.000357    0.00737    0.00018    3.6e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     26/300      13.8G      3.616      3.569      2.448         77        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407   0.000595     0.0123   0.000334   6.96e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     27/300      14.2G      3.594      3.574      2.456         94        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:10<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407    0.00155     0.0319    0.00081   0.000296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     28/300      13.8G      3.567      3.573      2.464         78        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407   0.000952     0.0197    0.00049   0.000202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     29/300      14.2G      3.558      3.579      2.478         82        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407    0.00131      0.027   0.000674   0.000158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     30/300      13.9G      3.573      3.567      2.414         82        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407    0.00131      0.027   0.000761   0.000306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     31/300      14.2G      3.507      3.528      2.404         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407    0.00143     0.0295   0.000738   0.000189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     32/300      13.8G      3.539      3.526      2.426         75        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407    0.00119     0.0246   0.000658   0.000184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     33/300      14.2G       3.53      3.539      2.377         76        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407    0.00226     0.0467    0.00159   0.000434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     34/300      13.8G      3.465      3.534      2.339         80        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407    0.00286      0.059    0.00181   0.000488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     35/300      14.2G      3.413      3.541      2.293         87        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407    0.00214     0.0442    0.00117   0.000311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     36/300      13.8G      3.372      3.519      2.311         94        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407    0.00155     0.0319   0.000895    0.00023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     37/300      14.2G      3.381      3.528      2.349         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407    0.00417      0.086    0.00275   0.000788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     38/300      13.8G      3.376      3.512      2.327         74        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407    0.00381     0.0786    0.00305    0.00106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     39/300      14.2G       3.39      3.453      2.288         94        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407    0.00131      0.027   0.000905   0.000312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     40/300      13.8G      3.356      3.457      2.281         80        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407    0.00321     0.0663    0.00207   0.000718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     41/300      14.2G       3.31      3.427      2.316         96        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407    0.00262     0.0541    0.00168   0.000448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     42/300      13.9G       3.33      3.381        2.3         74        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407    0.00595      0.123    0.00603    0.00143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     43/300      14.2G      3.272      3.386      2.289         75        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407    0.00781    0.00983    0.00193   0.000686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     44/300      13.9G       3.28      3.357       2.27         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407     0.0031     0.0639    0.00181   0.000527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     45/300      14.2G        3.2      3.227      2.214         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407    0.00334     0.0688     0.0019   0.000549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     46/300      13.8G      3.177        3.2      2.237         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407      0.104     0.0246     0.0177    0.00654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     47/300      14.2G      3.091      3.155       2.18         73        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407    0.00536      0.111    0.00875    0.00333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     48/300      13.8G      3.111      3.043      2.162         82        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407      0.126     0.0909     0.0351    0.00846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     49/300      14.2G      3.064      3.009      2.204         80        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407     0.0761     0.0344     0.0126     0.0036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     50/300      13.8G      3.056      2.976      2.184         71        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407      0.146     0.0786     0.0415     0.0107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     51/300      14.2G       3.02      3.012      2.159         79        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407     0.0821       0.12     0.0289    0.00879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     52/300      13.8G      2.962      2.905      2.088         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407     0.0212     0.0319     0.0104    0.00288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     53/300      14.2G      2.973      2.915      2.122         87        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407      0.197     0.0885     0.0692     0.0166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     54/300      13.8G      2.952      2.834      2.073         90        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407     0.0709       0.13     0.0346     0.0105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     55/300      14.2G       2.92      2.843      2.088         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407      0.219       0.16     0.0991     0.0358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     56/300      13.9G       2.89      2.794      2.047         79        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407     0.0728      0.187     0.0639     0.0187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     57/300      14.2G      2.884      2.804      2.049         82        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407      0.193      0.101     0.0767     0.0236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     58/300      13.8G      2.849      2.694      2.055        100        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407      0.225      0.196      0.106     0.0321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     59/300      14.2G      2.818      2.626       2.03         78        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407      0.248      0.189       0.12     0.0366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     60/300      13.9G       2.79      2.642      2.014         86        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407      0.335     0.0656     0.0586     0.0185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     61/300      14.2G      2.788      2.621      2.045         85        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407      0.253      0.216      0.146     0.0512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     62/300      13.8G      2.742      2.628      2.024         86        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407       0.26      0.147     0.0945      0.024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     63/300      14.2G      2.725      2.517      1.994         87        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407       0.29      0.225      0.176     0.0579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     64/300      13.8G      2.711      2.472      1.946         77        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407      0.264      0.241      0.143     0.0461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     65/300      14.2G      2.723      2.477       1.95         90        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407      0.343       0.13      0.121      0.041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     66/300      13.8G      2.638      2.422      1.964         86        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407      0.263      0.238      0.166     0.0599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     67/300      14.2G      2.651      2.384      1.979         78        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407      0.301      0.197      0.161     0.0501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     68/300      13.8G      2.628      2.398      1.921         97        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407      0.288      0.211      0.152     0.0491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     69/300      14.2G      2.681      2.407      1.936         77        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407      0.284      0.111      0.126     0.0448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     70/300      13.8G       2.64      2.399      1.904         85        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407        0.3      0.162      0.126     0.0487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     71/300      14.2G      2.519       2.26      1.871         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407      0.313      0.283       0.21      0.083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     72/300      13.9G      2.518      2.255      1.866         95        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407      0.312      0.172      0.148     0.0435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     73/300      14.2G      2.516      2.264      1.836         61        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407      0.395      0.241      0.225     0.0723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     74/300      13.8G       2.51      2.208      1.829         87        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407      0.483      0.301      0.308     0.0897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     75/300      14.2G      2.569      2.259      1.863         80        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407      0.312      0.224      0.168     0.0586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     76/300      13.8G      2.457      2.181      1.855         94        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407      0.347      0.371      0.296      0.108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     77/300      14.2G      2.466      2.211      1.788         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407      0.296      0.179      0.141     0.0415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     78/300      13.8G      2.417      2.102      1.798         82        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         84        407      0.328      0.312      0.237      0.085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     79/300      14.2G      2.408      2.092      1.763        143        640:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 8/11 [00:08<00:03,  1.07s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"ro3YTUP1KOJWZGcorPeR\")\n",
        "project = rf.workspace(\"roboflow-100\").project(\"vehicles-q0x2v\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"yolov8\")\n"
      ],
      "metadata": {
        "id": "n48mvbkAi2e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a594830e-bcab-46ee-d868-8f80fd9c9774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.41-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.7.4)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.2)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.53.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Downloading roboflow-1.1.41-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, python-dotenv, requests-toolbelt, roboflow\n",
            "Successfully installed filetype-1.2.0 python-dotenv-1.0.1 requests-toolbelt-1.0.0 roboflow-1.1.41\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Dependency ultralytics==8.0.196 is required but found version=8.2.81, to fix: `pip install ultralytics==8.0.196`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in vehicles-2 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 181871/181871 [00:06<00:00, 27432.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to vehicles-2 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8128/8128 [00:01<00:00, 4965.24it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=train model=yolov8m.pt data=/content/vehicles-2/data.yaml epochs=10 imgsz=640 plots=True"
      ],
      "metadata": {
        "id": "c4ZgVLMMi6V0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acd75ec5-1d74-430c-de86-19f53ae3b6a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt to 'yolov8m.pt'...\n",
            "100% 49.7M/49.7M [00:00<00:00, 72.1MB/s]\n",
            "Ultralytics YOLOv8.2.81 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=/content/vehicles-2/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 18.6MB/s]\n",
            "Overriding model.yaml nc=80 with nc=12\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3782644  ultralytics.nn.modules.head.Detect           [12, [192, 384, 576]]         \n",
            "Model summary: 295 layers, 25,863,268 parameters, 25,863,252 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 469/475 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100% 6.25M/6.25M [00:00<00:00, 118MB/s]\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/vehicles-2/train/labels... 2634 images, 1 backgrounds, 0 corrupt: 100% 2634/2634 [00:01<00:00, 2026.89it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/vehicles-2/train/images/adit_mp4-1357_jpg.rf.2f4228b88eed2a385c26be2238d05d8e.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/vehicles-2/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/vehicles-2/valid/labels... 966 images, 3 backgrounds, 0 corrupt: 100% 966/966 [00:01<00:00, 584.11it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/vehicles-2/valid/labels.cache\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000625, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/10       7.2G      1.339      1.552      1.149        118        640: 100% 165/165 [01:38<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 31/31 [00:14<00:00,  2.18it/s]\n",
            "                   all        966      13450      0.334      0.374      0.301      0.197\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/10      7.08G      1.257      1.016      1.116         97        640: 100% 165/165 [01:30<00:00,  1.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 31/31 [00:12<00:00,  2.51it/s]\n",
            "                   all        966      13450      0.335       0.49       0.37      0.244\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/10      7.16G      1.244     0.9142      1.122        114        640: 100% 165/165 [01:28<00:00,  1.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 31/31 [00:12<00:00,  2.48it/s]\n",
            "                   all        966      13450      0.357      0.443      0.358      0.234\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/10      7.19G      1.224     0.8393      1.117        115        640: 100% 165/165 [01:28<00:00,  1.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 31/31 [00:12<00:00,  2.55it/s]\n",
            "                   all        966      13450      0.397      0.482      0.376      0.251\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/10      7.05G      1.182     0.7641      1.097        123        640: 100% 165/165 [01:27<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 31/31 [00:12<00:00,  2.54it/s]\n",
            "                   all        966      13450      0.427        0.5      0.413      0.277\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/10      7.15G      1.161     0.7166      1.091        133        640: 100% 165/165 [01:28<00:00,  1.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 31/31 [00:12<00:00,  2.55it/s]\n",
            "                   all        966      13450       0.45      0.518      0.406      0.277\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/10      7.16G      1.134     0.6697      1.084        107        640: 100% 165/165 [01:27<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 31/31 [00:12<00:00,  2.57it/s]\n",
            "                   all        966      13450      0.459      0.535       0.43      0.297\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/10      7.16G       1.11     0.6234      1.071        106        640: 100% 165/165 [01:27<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 31/31 [00:11<00:00,  2.76it/s]\n",
            "                   all        966      13450      0.497      0.566      0.447       0.31\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/10      7.08G       1.08     0.5863      1.058        113        640: 100% 165/165 [01:36<00:00,  1.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 31/31 [00:12<00:00,  2.54it/s]\n",
            "                   all        966      13450      0.501       0.54      0.439      0.307\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/10      7.15G      1.059     0.5582      1.043        125        640: 100% 165/165 [01:28<00:00,  1.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 31/31 [00:12<00:00,  2.56it/s]\n",
            "                   all        966      13450      0.502      0.569       0.44       0.31\n",
            "\n",
            "10 epochs completed in 0.298 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 52.0MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 52.0MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.81 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 218 layers, 25,846,708 parameters, 0 gradients, 78.7 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 31/31 [00:26<00:00,  1.19it/s]\n",
            "                   all        966      13450      0.496      0.566      0.447      0.309\n",
            "               big bus        210        273       0.74      0.459      0.716      0.541\n",
            "             big truck        404       1162      0.786      0.466       0.66      0.425\n",
            "                bus-l-          8          8      0.044      0.625     0.0365     0.0171\n",
            "                bus-s-         12         12      0.232      0.833       0.22      0.164\n",
            "                   car        927       8537      0.881      0.688      0.833      0.509\n",
            "             mid truck        118        257      0.675      0.401      0.391      0.286\n",
            "             small bus         43         49      0.119      0.143     0.0804     0.0443\n",
            "           small truck        517       1721      0.709      0.542      0.625      0.388\n",
            "              truck-l-        266        433      0.429      0.658      0.466      0.348\n",
            "              truck-m-        331        629       0.42      0.688      0.419      0.313\n",
            "              truck-s-        147        221      0.389      0.584      0.284      0.188\n",
            "             truck-xl-        110        148      0.534      0.705      0.633       0.49\n",
            "Speed: 0.3ms preprocess, 7.8ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"sparseml[ultralytics]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LEpNnSVQZrM8",
        "outputId": "e4576bd4-fb44-4c63-ef6f-27ecfe56fc73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sparseml[ultralytics]\n",
            "  Downloading sparseml-1.8.0-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting sparsezoo>=1.7.0 (from sparseml[ultralytics])\n",
            "  Downloading sparsezoo-1.8.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: pyyaml>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from sparseml[ultralytics]) (6.0.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from sparseml[ultralytics]) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from sparseml[ultralytics]) (3.7.1)\n",
            "Collecting merge-args>=0.1.0 (from sparseml[ultralytics])\n",
            "  Downloading merge_args-0.1.5-py2.py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting onnx<1.15.0,>=1.5.0 (from sparseml[ultralytics])\n",
            "  Downloading onnx-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from sparseml[ultralytics]) (2.1.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from sparseml[ultralytics]) (24.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from sparseml[ultralytics]) (5.9.5)\n",
            "Collecting pydantic<2.8.0,>=2.0.0 (from sparseml[ultralytics])\n",
            "  Downloading pydantic-2.7.4-py3-none-any.whl.metadata (109 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m109.4/109.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sparseml[ultralytics]) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from sparseml[ultralytics]) (1.3.2)\n",
            "Requirement already satisfied: tqdm>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from sparseml[ultralytics]) (4.66.5)\n",
            "Collecting toposort>=1.0 (from sparseml[ultralytics])\n",
            "  Downloading toposort-1.10-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting GPUtil>=1.4.0 (from sparseml[ultralytics])\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf<=3.20.3,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from sparseml[ultralytics]) (3.20.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from sparseml[ultralytics]) (8.1.7)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from sparseml[ultralytics]) (1.13.1)\n",
            "Collecting ultralytics==8.0.124 (from sparseml[ultralytics])\n",
            "  Downloading ultralytics-8.0.124-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from sparseml[ultralytics]) (2.3.1+cu121)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.124->sparseml[ultralytics]) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.124->sparseml[ultralytics]) (9.4.0)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.124->sparseml[ultralytics]) (0.18.1+cu121)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.124->sparseml[ultralytics]) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->sparseml[ultralytics]) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->sparseml[ultralytics]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->sparseml[ultralytics]) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->sparseml[ultralytics]) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->sparseml[ultralytics]) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->sparseml[ultralytics]) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx<1.15.0,>=1.5.0->sparseml[ultralytics]) (4.12.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.0->sparseml[ultralytics]) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.0->sparseml[ultralytics]) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.8.0,>=2.0.0->sparseml[ultralytics]) (0.7.0)\n",
            "Collecting pydantic-core==2.18.4 (from pydantic<2.8.0,>=2.0.0->sparseml[ultralytics])\n",
            "  Downloading pydantic_core-2.18.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->sparseml[ultralytics]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->sparseml[ultralytics]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->sparseml[ultralytics]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->sparseml[ultralytics]) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->sparseml[ultralytics]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->sparseml[ultralytics]) (3.5.0)\n",
            "Collecting py-machineid>=0.3.0 (from sparsezoo>=1.7.0->sparseml[ultralytics])\n",
            "  Downloading py_machineid-0.6.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: geocoder>=1.38.0 in /usr/local/lib/python3.10/dist-packages (from sparsezoo>=1.7.0->sparseml[ultralytics]) (1.38.1)\n",
            "Collecting onnxruntime>=1.0.0 (from sparsezoo>=1.7.0->sparseml[ultralytics])\n",
            "  Downloading onnxruntime-1.19.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->sparseml[ultralytics]) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->sparseml[ultralytics]) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->sparseml[ultralytics]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->sparseml[ultralytics]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->sparseml[ultralytics]) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->sparseml[ultralytics]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->sparseml[ultralytics]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->sparseml[ultralytics]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->sparseml[ultralytics]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->sparseml[ultralytics]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->sparseml[ultralytics]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->sparseml[ultralytics]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->sparseml[ultralytics]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->sparseml[ultralytics]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->sparseml[ultralytics]) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->sparseml[ultralytics]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->sparseml[ultralytics]) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.0->sparseml[ultralytics]) (12.6.20)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from geocoder>=1.38.0->sparsezoo>=1.7.0->sparseml[ultralytics]) (1.0.0)\n",
            "Requirement already satisfied: ratelim in /usr/local/lib/python3.10/dist-packages (from geocoder>=1.38.0->sparsezoo>=1.7.0->sparseml[ultralytics]) (0.1.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from geocoder>=1.38.0->sparsezoo>=1.7.0->sparseml[ultralytics]) (1.16.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.0.0->sparsezoo>=1.7.0->sparseml[ultralytics])\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.0.0->sparsezoo>=1.7.0->sparseml[ultralytics]) (24.3.25)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->sparseml[ultralytics]) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->sparseml[ultralytics]) (1.3.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.0.0->sparsezoo>=1.7.0->sparseml[ultralytics])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ratelim->geocoder>=1.38.0->sparsezoo>=1.7.0->sparseml[ultralytics]) (4.4.2)\n",
            "Downloading ultralytics-8.0.124-py3-none-any.whl (612 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m612.6/612.6 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading merge_args-0.1.5-py2.py3-none-any.whl (6.0 kB)\n",
            "Downloading onnx-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.7.4-py3-none-any.whl (409 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m409.0/409.0 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.18.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sparsezoo-1.8.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m177.8/177.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading toposort-1.10-py3-none-any.whl (8.5 kB)\n",
            "Downloading sparseml-1.8.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.19.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py_machineid-0.6.0-py3-none-any.whl (4.9 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=ea89a05aed4c8df8eb18f5ebcb00dcce1c5c9bb4b5a78487730fb9197c0444a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: toposort, py-machineid, merge-args, GPUtil, pydantic-core, onnx, humanfriendly, pydantic, coloredlogs, onnxruntime, sparsezoo, ultralytics, sparseml\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.20.1\n",
            "    Uninstalling pydantic_core-2.20.1:\n",
            "      Successfully uninstalled pydantic_core-2.20.1\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.8.2\n",
            "    Uninstalling pydantic-2.8.2:\n",
            "      Successfully uninstalled pydantic-2.8.2\n",
            "  Attempting uninstall: ultralytics\n",
            "    Found existing installation: ultralytics 8.2.81\n",
            "    Uninstalling ultralytics-8.2.81:\n",
            "      Successfully uninstalled ultralytics-8.2.81\n",
            "Successfully installed GPUtil-1.4.0 coloredlogs-15.0.1 humanfriendly-10.0 merge-args-0.1.5 onnx-1.14.1 onnxruntime-1.19.0 py-machineid-0.6.0 pydantic-2.7.4 pydantic-core-2.18.4 sparseml-1.8.0 sparsezoo-1.8.1 toposort-1.10 ultralytics-8.0.124\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ultralytics"
                ]
              },
              "id": "2156068c390f4e749d9f63c3c017a181"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sparseml.ultralytics.train --model \"zoo:cv/detection/yolov8-m/pytorch/ultralytics/coco/pruned80-none\" --recipe \"zoo:cv/detection/yolov8-m/pytorch/ultralytics/voc/pruned80_quant-none\" --data /content/vehicles-2/data.yaml --recipe_args '{\"num_epochs\":10, \"qat_start_epoch\": 5, \"observer_freeze_epoch\": 7, \"bn_freeze_epoch\": 7}' --batch 16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKC6EGXye11x",
        "outputId": "14bf61c5-54c4-48c9-ff23-883be09da524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3822016  ultralytics.nn.modules.head.Detect           [80, [192, 384, 576]]         \n",
            "Model summary: 295 layers, 25902640 parameters, 25902624 gradients, 79.3 GFLOPs\n",
            "\n",
            "Applying structure from sparseml checkpoint at epoch 83\n",
            "Loaded previous weights from checkpoint\n",
            "WARNING âš ï¸ 'hide_labels' is deprecated and will be removed in 'ultralytics 8.2' in the future. Please use 'show_labels' instead.\n",
            "WARNING âš ï¸ 'hide_conf' is deprecated and will be removed in 'ultralytics 8.2' in the future. Please use 'show_conf' instead.\n",
            "WARNING âš ï¸ 'line_thickness' is deprecated and will be removed in 'ultralytics 8.2' in the future. Please use 'line_width' instead.\n",
            "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mrecipe=zoo:cv/detection/yolov8-m/pytorch/ultralytics/voc/pruned80_quant-none, recipe_args={\"num_epochs\":10, \"qat_start_epoch\": 5, \"observer_freeze_epoch\": 7, \"bn_freeze_epoch\": 7}, datasets_dir=None, task=detect, mode=train, model=zoo:cv/detection/yolov8-m/pytorch/ultralytics/coco/pruned80-none, data=/content/vehicles-2/data.yaml, epochs=100, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=False, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, min_memory=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=ultralytics/assets/, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=False, show_conf=False, vid_stride=1, line_width=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, save_dir=runs/detect/train6\n",
            "Overriding model.yaml nc=80 with nc=12\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3782644  ultralytics.nn.modules.head.Detect           [12, [192, 384, 576]]         \n",
            "Model summary: 295 layers, 25863268 parameters, 25863252 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 469/475 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train6', view at http://localhost:6006/\n",
            "Received torch.nn.Module, not loading from checkpoint\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/vehicles-2/train/labels.cache... 2634 images, 1 backgrounds, 0 corrupt: 100% 2634/2634 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/vehicles-2/train/images/adit_mp4-1357_jpg.rf.2f4228b88eed2a385c26be2238d05d8e.jpg: 2 duplicate labels removed\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/core/composition.py:161: UserWarning: Got processor for bboxes, but no transform to process it.\n",
            "  self._set_keys()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/vehicles-2/valid/labels.cache... 966 images, 3 backgrounds, 0 corrupt: 100% 966/966 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/detect/train6/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/vehicles-2/valid/labels.cache... 966 images, 3 backgrounds, 0 corrupt: 100% 966/966 [00:00<?, ?it/s]\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/sparseml/yolov8/trainers.py:320: UserWarning: Unable to import wandb for logging\n",
            "  warnings.warn(\"Unable to import wandb for logging\")\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train6\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/core/composition.py:161: UserWarning: Got processor for bboxes, but no transform to process it.\n",
            "  self._set_keys()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/10      6.94G      1.394      1.909      1.201        119        640: 100% 165/165 [01:47<00:00,  1.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 242/242 [00:31<00:00,  7.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/10       7.3G      1.283      1.122      1.128         94        640: 100% 165/165 [01:39<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 242/242 [00:31<00:00,  7.69it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/10      7.54G      1.249     0.9912      1.102        110        640: 100% 165/165 [01:38<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 242/242 [00:30<00:00,  7.84it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/10      7.16G       1.23     0.8734      1.102        115        640: 100% 165/165 [01:37<00:00,  1.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 242/242 [00:30<00:00,  7.83it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/10      7.29G      1.195     0.7918      1.077        124        640: 100% 165/165 [01:37<00:00,  1.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 242/242 [00:31<00:00,  7.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/10      14.5G      1.195     0.7853      1.078        131        640: 100% 165/165 [04:05<00:00,  1.49s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 242/242 [01:37<00:00,  2.48it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/10      13.9G      1.193     0.7871      1.079        106        640: 100% 165/165 [04:05<00:00,  1.49s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 242/242 [01:37<00:00,  2.48it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/10      14.4G      1.185     0.7697      1.071        107        640: 100% 165/165 [03:27<00:00,  1.26s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 242/242 [00:55<00:00,  4.37it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/10      13.8G      1.182     0.7669      1.074        114        640: 100% 165/165 [03:28<00:00,  1.26s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 242/242 [00:54<00:00,  4.41it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/10      14.1G      1.185     0.7695      1.077        126        640: 100% 165/165 [03:26<00:00,  1.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 242/242 [01:01<00:00,  3.92it/s]\n",
            "\n",
            "10 epochs completed in 0.621 hours.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sparseml.ultralytics.export_onnx --model /content/runs/detect/train6/weights/best.pt --save_dir yolov8-m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0x_2bTjguD-m",
        "outputId": "2f3f8eec-5ad6-40de-bc67-61b52cf79692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3782644  ultralytics.nn.modules.head.Detect           [12, [192, 384, 576]]         \n",
            "Model summary: 295 layers, 25863268 parameters, 25863252 gradients, 79.1 GFLOPs\n",
            "\n",
            "Applying structure from sparseml checkpoint at epoch 3\n",
            "2024-08-23 10:12:01 sparseml.pytorch.utils.logger INFO     Logging all SparseML modifier-level logs to sparse_logs/23-08-2024_10.12.01.log\n",
            "Loaded previous weights from checkpoint\n",
            "Source: 'sparseml' detected; Exporting model from SparseML checkpoint...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:823: UserWarning: It is recommended that constant folding be turned off ('do_constant_folding=False') when exporting the model in training-amenable mode, i.e. with 'training=TrainingMode.TRAIN' or 'training=TrainingMode.PRESERVE' (when model is in training mode). Otherwise, some learnable model parameters may not translate correctly in the exported ONNX model because constant folding mutates model parameters. Please consider turning off constant folding or setting the training=TrainingMode.EVAL.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py:50: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  elif self.dynamic or self.shape != shape:\n",
            "2024-08-23 10:12:07 sparseml.pytorch.utils.exporter INFO     Created deployment folder at /content/yolov8-m/deployment\n",
            "2024-08-23 10:12:07 sparseml.pytorch.utils.exporter INFO     Saved model.onnx in the deployment folder at /content/yolov8-m/deployment/model.onnx\n",
            "2024-08-23 10:12:07 sparseml.pytorch.utils.exporter INFO     Created config.json file at /content/yolov8-m/deployment\n",
            "Recipe checkpoint detected, saving the recipe to the deployment directory /content/yolov8-m/deployment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepsparse\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5vc0fAuwFzT",
        "outputId": "1282f707-391c-4cdd-f139-690f5aad9e30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepsparse\n",
            "  Downloading deepsparse-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: sparsezoo~=1.8.0 in /usr/local/lib/python3.10/dist-packages (from deepsparse) (1.8.1)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.10/dist-packages (from deepsparse) (1.26.4)\n",
            "Requirement already satisfied: onnx<1.15.0,>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from deepsparse) (1.14.1)\n",
            "Requirement already satisfied: pydantic~=2.0 in /usr/local/lib/python3.10/dist-packages (from deepsparse) (2.7.4)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from deepsparse) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from deepsparse) (4.66.5)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from deepsparse) (3.20.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from deepsparse) (8.1.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx<1.15.0,>=1.5.0->deepsparse) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic~=2.0->deepsparse) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic~=2.0->deepsparse) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->deepsparse) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->deepsparse) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->deepsparse) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->deepsparse) (2024.7.4)\n",
            "Requirement already satisfied: pyyaml>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from sparsezoo~=1.8.0->deepsparse) (6.0.2)\n",
            "Requirement already satisfied: pandas>1.3 in /usr/local/lib/python3.10/dist-packages (from sparsezoo~=1.8.0->deepsparse) (2.1.4)\n",
            "Requirement already satisfied: py-machineid>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from sparsezoo~=1.8.0->deepsparse) (0.6.0)\n",
            "Requirement already satisfied: geocoder>=1.38.0 in /usr/local/lib/python3.10/dist-packages (from sparsezoo~=1.8.0->deepsparse) (1.38.1)\n",
            "Requirement already satisfied: onnxruntime>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from sparsezoo~=1.8.0->deepsparse) (1.19.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from geocoder>=1.38.0->sparsezoo~=1.8.0->deepsparse) (1.0.0)\n",
            "Requirement already satisfied: ratelim in /usr/local/lib/python3.10/dist-packages (from geocoder>=1.38.0->sparsezoo~=1.8.0->deepsparse) (0.1.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from geocoder>=1.38.0->sparsezoo~=1.8.0->deepsparse) (1.16.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.0.0->sparsezoo~=1.8.0->deepsparse) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.0.0->sparsezoo~=1.8.0->deepsparse) (24.3.25)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.0.0->sparsezoo~=1.8.0->deepsparse) (24.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.0.0->sparsezoo~=1.8.0->deepsparse) (1.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>1.3->sparsezoo~=1.8.0->deepsparse) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>1.3->sparsezoo~=1.8.0->deepsparse) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>1.3->sparsezoo~=1.8.0->deepsparse) (2024.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.0.0->sparsezoo~=1.8.0->deepsparse) (10.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ratelim->geocoder>=1.38.0->sparsezoo~=1.8.0->deepsparse) (4.4.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.0.0->sparsezoo~=1.8.0->deepsparse) (1.3.0)\n",
            "Downloading deepsparse-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deepsparse\n",
            "Successfully installed deepsparse-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepsparse[yolov8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ow1erQMyxOry",
        "outputId": "92505743-4290-4525-e6d2-8f3fa8c69fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deepsparse[yolov8] in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Requirement already satisfied: sparsezoo~=1.8.0 in /usr/local/lib/python3.10/dist-packages (from deepsparse[yolov8]) (1.8.1)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.10/dist-packages (from deepsparse[yolov8]) (1.26.4)\n",
            "Requirement already satisfied: onnx<1.15.0,>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from deepsparse[yolov8]) (1.14.1)\n",
            "Requirement already satisfied: pydantic~=2.0 in /usr/local/lib/python3.10/dist-packages (from deepsparse[yolov8]) (2.7.4)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from deepsparse[yolov8]) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from deepsparse[yolov8]) (4.66.5)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from deepsparse[yolov8]) (3.20.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from deepsparse[yolov8]) (8.1.7)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from deepsparse[yolov8]) (0.18.1+cu121)\n",
            "Collecting opencv-python<=4.6.0.66 (from deepsparse[yolov8])\n",
            "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: ultralytics==8.0.124 in /usr/local/lib/python3.10/dist-packages (from deepsparse[yolov8]) (8.0.124)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.124->deepsparse[yolov8]) (3.7.1)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.124->deepsparse[yolov8]) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.124->deepsparse[yolov8]) (6.0.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.124->deepsparse[yolov8]) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.124->deepsparse[yolov8]) (2.3.1+cu121)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.124->deepsparse[yolov8]) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.124->deepsparse[yolov8]) (0.13.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.124->deepsparse[yolov8]) (5.9.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx<1.15.0,>=1.5.0->deepsparse[yolov8]) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic~=2.0->deepsparse[yolov8]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic~=2.0->deepsparse[yolov8]) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->deepsparse[yolov8]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->deepsparse[yolov8]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->deepsparse[yolov8]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->deepsparse[yolov8]) (2024.7.4)\n",
            "Requirement already satisfied: py-machineid>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from sparsezoo~=1.8.0->deepsparse[yolov8]) (0.6.0)\n",
            "Requirement already satisfied: geocoder>=1.38.0 in /usr/local/lib/python3.10/dist-packages (from sparsezoo~=1.8.0->deepsparse[yolov8]) (1.38.1)\n",
            "Requirement already satisfied: onnxruntime>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from sparsezoo~=1.8.0->deepsparse[yolov8]) (1.19.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.124->deepsparse[yolov8]) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.124->deepsparse[yolov8]) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.124->deepsparse[yolov8]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.124->deepsparse[yolov8]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.124->deepsparse[yolov8]) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.124->deepsparse[yolov8]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.124->deepsparse[yolov8]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.124->deepsparse[yolov8]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.124->deepsparse[yolov8]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.124->deepsparse[yolov8]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.124->deepsparse[yolov8]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.124->deepsparse[yolov8]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.124->deepsparse[yolov8]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.124->deepsparse[yolov8]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.124->deepsparse[yolov8]) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.124->deepsparse[yolov8]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.124->deepsparse[yolov8]) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.0->ultralytics==8.0.124->deepsparse[yolov8]) (12.6.20)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from geocoder>=1.38.0->sparsezoo~=1.8.0->deepsparse[yolov8]) (1.0.0)\n",
            "Requirement already satisfied: ratelim in /usr/local/lib/python3.10/dist-packages (from geocoder>=1.38.0->sparsezoo~=1.8.0->deepsparse[yolov8]) (0.1.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from geocoder>=1.38.0->sparsezoo~=1.8.0->deepsparse[yolov8]) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.124->deepsparse[yolov8]) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.124->deepsparse[yolov8]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.124->deepsparse[yolov8]) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.124->deepsparse[yolov8]) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.124->deepsparse[yolov8]) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.124->deepsparse[yolov8]) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.124->deepsparse[yolov8]) (2.8.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.0.0->sparsezoo~=1.8.0->deepsparse[yolov8]) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.0.0->sparsezoo~=1.8.0->deepsparse[yolov8]) (24.3.25)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.0.124->deepsparse[yolov8]) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.0.124->deepsparse[yolov8]) (2024.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.0.0->sparsezoo~=1.8.0->deepsparse[yolov8]) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->ultralytics==8.0.124->deepsparse[yolov8]) (2.1.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ratelim->geocoder>=1.38.0->sparsezoo~=1.8.0->deepsparse[yolov8]) (4.4.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->ultralytics==8.0.124->deepsparse[yolov8]) (1.3.0)\n",
            "Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.9/60.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.10.0.84\n",
            "    Uninstalling opencv-python-4.10.0.84:\n",
            "      Successfully uninstalled opencv-python-4.10.0.84\n",
            "Successfully installed opencv-python-4.6.0.66\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cv2"
                ]
              },
              "id": "a8361273e3f9482dac08fd5e94ab7886"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/neuralmagic/deepsparse.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSf7PMutxb74",
        "outputId": "9d0fa9c3-804d-44e5-d4a2-84298872faf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deepsparse'...\n",
            "remote: Enumerating objects: 23109, done.\u001b[K\n",
            "remote: Counting objects: 100% (4900/4900), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1191/1191), done.\u001b[K\n",
            "remote: Total 23109 (delta 4409), reused 3907 (delta 3705), pack-reused 18209 (from 1)\u001b[K\n",
            "Receiving objects: 100% (23109/23109), 140.69 MiB | 33.43 MiB/s, done.\n",
            "Resolving deltas: 100% (16580/16580), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/deepsparse/src/deepsparse/yolov8\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IK9XS0NxlF5",
        "outputId": "78c347a2-1e93-47d3-c8e8-833b59063a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deepsparse/src/deepsparse/yolov8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python annotate.py --source \"/content/vehicles-2/test/images/adit_mp4-1002_jpg.rf.5e4018e963af1251b3f7e6fd487c479e.jpg\" \\\n",
        " --model_filepath \"/content/yolov8-m/deployment/model.onnx\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FlWblsfxUlU",
        "outputId": "07cbb619-c014-4f30-e557-3c50ddf495ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-08-23 10:41:18 deepsparse.utils.annotate INFO     Results will be saved to annotation-results/deepsparse-annotations/deepsparse-annotations-002\n",
            "2024-08-23 10:41:18 deepsparse.pipeline WARNING  Could not create v2 'yolov8' pipeline, trying legacy\n",
            "DeepSparse, Copyright 2021-present / Neuralmagic, Inc. version: 1.8.0 COMMUNITY | (e3778e93) (release) (optimized) (system=avx512, binary=avx512)\n",
            "2024-08-23 10:41:40 __main__     INFO     Total inference time: 0.51 seconds\n",
            "2024-08-23 10:41:40 __main__     INFO     Results saved to annotation-results/deepsparse-annotations/deepsparse-annotations-002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from deepsparse import Pipeline\n",
        "\n",
        "# Define all the class names\n",
        "class_names = {\n",
        "    \"0\": \"big bus\",\n",
        "    \"1\": \"big truck\",\n",
        "    \"2\": \"bus-l-\",\n",
        "    \"3\": \"bus-s-\",\n",
        "    \"4\": \"car\",\n",
        "    \"5\": \"mid truck\",\n",
        "    \"6\": \"small bus\",\n",
        "    \"7\": \"small truck\",\n",
        "    \"8\": \"truck-l-\",\n",
        "    \"9\": \"truck-m-\",\n",
        "    \"10\": \"truck-s-\",\n",
        "    \"11\": \"truck-xl-\"\n",
        "}\n",
        "\n",
        "# Create the YOLO pipeline with the correct model path and class names\n",
        "yolo_pipeline = Pipeline.create(\n",
        "    task=\"yolo\",\n",
        "    model_path=\"/content/yolov8-m/deployment/model.onnx\",  # Path to the local ONNX model\n",
        "    class_names=class_names  # Provide all class names\n",
        ")\n",
        "\n",
        "# List of images to run inference on\n",
        "images = [\"/content/vehicles-2/test/images/adit_mp4-1002_jpg.rf.5e4018e963af1251b3f7e6fd487c479e.jpg\"]\n",
        "\n",
        "# Measure the time taken for inference\n",
        "start_time = time.time()\n",
        "\n",
        "# Run inference\n",
        "pipeline_outputs = yolo_pipeline(images=images)\n",
        "\n",
        "# Calculate the total inference time\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "\n",
        "# Print the results\n",
        "print(\"Inference Labels:\", pipeline_outputs.labels)\n",
        "print(f\"Total inference time: {total_time:.4f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "CGufeUmJtUEY",
        "outputId": "08bad0da-3d27-42dc-fa8c-940d4f0fa438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-08-23 10:20:41 deepsparse.pipeline WARNING  Could not create v2 'yolo' pipeline, trying legacy\n",
            "WARNING:deepsparse.pipeline:Could not create v2 'yolo' pipeline, trying legacy\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'8024'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-f6987487b35c>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Run inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mpipeline_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myolo_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Calculate the total inference time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/deepsparse/legacy/pipeline.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;31m# ------ POSTPROCESSING ------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInferenceStages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOST_PROCESS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0mpipeline_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_engine_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/deepsparse/yolo/pipelines.py\u001b[0m in \u001b[0;36mprocess_engine_outputs\u001b[0;34m(self, engine_outputs, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m                     \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 ]\n\u001b[0;32m--> 309\u001b[0;31m                 batch_class_names = [\n\u001b[0m\u001b[1;32m    310\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_string\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mlabel_string\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_labels_as_strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/deepsparse/yolo/pipelines.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    308\u001b[0m                 ]\n\u001b[1;32m    309\u001b[0m                 batch_class_names = [\n\u001b[0;32m--> 310\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_string\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mlabel_string\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_labels_as_strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                 ]\n",
            "\u001b[0;31mKeyError\u001b[0m: '8024'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO(\"/content/runs/detect/train2/weights/best.pt\")\n",
        "\n",
        "# Export the model to TFLite format\n",
        "model.export(format=\"tflite\")"
      ],
      "metadata": {
        "id": "cs1yQt-ArWet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf"
      ],
      "metadata": {
        "id": "9I9IdejZrYM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"W6D3zFpw6pKUK31pvev4\")\n",
        "project = rf.workspace(\"vnu-ehycy\").project(\"carbus-zrvi1\")\n",
        "dataset = project.version(3).download(\"yolov5\")\n"
      ],
      "metadata": {
        "id": "YR_-PXpPUKHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BziXMsMxJBsz"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/ultralytics/ultralytics.git\n",
        "%cd /content/ultralytics\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4eASbcWkQBq"
      },
      "source": [
        "## Inference with Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSy4eGotZqXU"
      },
      "outputs": [],
      "source": [
        "%%writefile /content/ultralytics/ultralytics/engine/results.py\n",
        "\n",
        "# Your updated Python code here\n",
        "# Ultralytics YOLO ðŸš€, AGPL-3.0 license\n",
        "\"\"\"\n",
        "Ultralytics Results, Boxes and Masks classes for handling inference results.\n",
        "\n",
        "Usage: See https://docs.ultralytics.com/modes/predict/\n",
        "\"\"\"\n",
        "\n",
        "from copy import deepcopy\n",
        "from functools import lru_cache\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from ultralytics.data.augment import LetterBox\n",
        "from ultralytics.utils import LOGGER, SimpleClass, ops\n",
        "from ultralytics.utils.plotting import Annotator, colors, save_one_box\n",
        "from ultralytics.utils.torch_utils import smart_inference_mode\n",
        "\n",
        "\n",
        "class BaseTensor(SimpleClass):\n",
        "    \"\"\"Base tensor class with additional methods for easy manipulation and device handling.\"\"\"\n",
        "\n",
        "    def __init__(self, data, orig_shape) -> None:\n",
        "        \"\"\"\n",
        "        Initialize BaseTensor with data and original shape.\n",
        "\n",
        "        Args:\n",
        "            data (torch.Tensor | np.ndarray): Predictions, such as bboxes, masks and keypoints.\n",
        "            orig_shape (tuple): Original shape of image.\n",
        "        \"\"\"\n",
        "        assert isinstance(data, (torch.Tensor, np.ndarray))\n",
        "        self.data = data\n",
        "        self.orig_shape = orig_shape\n",
        "\n",
        "    @property\n",
        "    def shape(self):\n",
        "        \"\"\"Return the shape of the data tensor.\"\"\"\n",
        "        return self.data.shape\n",
        "\n",
        "    def cpu(self):\n",
        "        \"\"\"Return a copy of the tensor on CPU memory.\"\"\"\n",
        "        return self if isinstance(self.data, np.ndarray) else self.__class__(self.data.cpu(), self.orig_shape)\n",
        "\n",
        "    def numpy(self):\n",
        "        \"\"\"Return a copy of the tensor as a numpy array.\"\"\"\n",
        "        return self if isinstance(self.data, np.ndarray) else self.__class__(self.data.numpy(), self.orig_shape)\n",
        "\n",
        "    def cuda(self):\n",
        "        \"\"\"Return a copy of the tensor on GPU memory.\"\"\"\n",
        "        return self.__class__(torch.as_tensor(self.data).cuda(), self.orig_shape)\n",
        "\n",
        "    def to(self, *args, **kwargs):\n",
        "        \"\"\"Return a copy of the tensor with the specified device and dtype.\"\"\"\n",
        "        return self.__class__(torch.as_tensor(self.data).to(*args, **kwargs), self.orig_shape)\n",
        "\n",
        "    def __len__(self):  # override len(results)\n",
        "        \"\"\"Return the length of the data tensor.\"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Return a BaseTensor with the specified index of the data tensor.\"\"\"\n",
        "        return self.__class__(self.data[idx], self.orig_shape)\n",
        "\n",
        "\n",
        "class Results(SimpleClass):\n",
        "    \"\"\"\n",
        "    A class for storing and manipulating inference results.\n",
        "\n",
        "    Args:\n",
        "        orig_img (numpy.ndarray): The original image as a numpy array.\n",
        "        path (str): The path to the image file.\n",
        "        names (dict): A dictionary of class names.\n",
        "        boxes (torch.tensor, optional): A 2D tensor of bounding box coordinates for each detection.\n",
        "        masks (torch.tensor, optional): A 3D tensor of detection masks, where each mask is a binary image.\n",
        "        probs (torch.tensor, optional): A 1D tensor of probabilities of each class for classification task.\n",
        "        keypoints (List[List[float]], optional): A list of detected keypoints for each object.\n",
        "\n",
        "    Attributes:\n",
        "        orig_img (numpy.ndarray): The original image as a numpy array.\n",
        "        orig_shape (tuple): The original image shape in (height, width) format.\n",
        "        boxes (Boxes, optional): A Boxes object containing the detection bounding boxes.\n",
        "        masks (Masks, optional): A Masks object containing the detection masks.\n",
        "        probs (Probs, optional): A Probs object containing probabilities of each class for classification task.\n",
        "        keypoints (Keypoints, optional): A Keypoints object containing detected keypoints for each object.\n",
        "        speed (dict): A dictionary of preprocess, inference, and postprocess speeds in milliseconds per image.\n",
        "        names (dict): A dictionary of class names.\n",
        "        path (str): The path to the image file.\n",
        "        _keys (tuple): A tuple of attribute names for non-empty attributes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, orig_img, path, names, boxes=None, masks=None, probs=None, keypoints=None) -> None:\n",
        "        \"\"\"Initialize the Results class.\"\"\"\n",
        "        self.orig_img = orig_img\n",
        "        self.orig_shape = orig_img.shape[:2]\n",
        "        self.boxes = Boxes(boxes, self.orig_shape) if boxes is not None else None  # native size boxes\n",
        "        self.masks = Masks(masks, self.orig_shape) if masks is not None else None  # native size or imgsz masks\n",
        "        self.probs = Probs(probs) if probs is not None else None\n",
        "        self.keypoints = Keypoints(keypoints, self.orig_shape) if keypoints is not None else None\n",
        "        self.speed = {'preprocess': None, 'inference': None, 'postprocess': None}  # milliseconds per image\n",
        "        self.names = names\n",
        "        self.path = path\n",
        "        self.save_dir = None\n",
        "        self._keys = 'boxes', 'masks', 'probs', 'keypoints'\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Return a Results object for the specified index.\"\"\"\n",
        "        return self._apply('__getitem__', idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the number of detections in the Results object.\"\"\"\n",
        "        for k in self._keys:\n",
        "            v = getattr(self, k)\n",
        "            if v is not None:\n",
        "                return len(v)\n",
        "\n",
        "    def update(self, boxes=None, masks=None, probs=None):\n",
        "        \"\"\"Update the boxes, masks, and probs attributes of the Results object.\"\"\"\n",
        "        if boxes is not None:\n",
        "            self.boxes = Boxes(ops.clip_boxes(boxes, self.orig_shape), self.orig_shape)\n",
        "        if masks is not None:\n",
        "            self.masks = Masks(masks, self.orig_shape)\n",
        "        if probs is not None:\n",
        "            self.probs = probs\n",
        "\n",
        "    def _apply(self, fn, *args, **kwargs):\n",
        "        \"\"\"\n",
        "        Applies a function to all non-empty attributes and returns a new Results object with modified attributes. This\n",
        "        function is internally called by methods like .to(), .cuda(), .cpu(), etc.\n",
        "\n",
        "        Args:\n",
        "            fn (str): The name of the function to apply.\n",
        "            *args: Variable length argument list to pass to the function.\n",
        "            **kwargs: Arbitrary keyword arguments to pass to the function.\n",
        "\n",
        "        Returns:\n",
        "            Results: A new Results object with attributes modified by the applied function.\n",
        "        \"\"\"\n",
        "        r = self.new()\n",
        "        for k in self._keys:\n",
        "            v = getattr(self, k)\n",
        "            if v is not None:\n",
        "                setattr(r, k, getattr(v, fn)(*args, **kwargs))\n",
        "        return r\n",
        "\n",
        "    def cpu(self):\n",
        "        \"\"\"Return a copy of the Results object with all tensors on CPU memory.\"\"\"\n",
        "        return self._apply('cpu')\n",
        "\n",
        "    def numpy(self):\n",
        "        \"\"\"Return a copy of the Results object with all tensors as numpy arrays.\"\"\"\n",
        "        return self._apply('numpy')\n",
        "\n",
        "    def cuda(self):\n",
        "        \"\"\"Return a copy of the Results object with all tensors on GPU memory.\"\"\"\n",
        "        return self._apply('cuda')\n",
        "\n",
        "    def to(self, *args, **kwargs):\n",
        "        \"\"\"Return a copy of the Results object with tensors on the specified device and dtype.\"\"\"\n",
        "        return self._apply('to', *args, **kwargs)\n",
        "\n",
        "    def new(self):\n",
        "        \"\"\"Return a new Results object with the same image, path, and names.\"\"\"\n",
        "        return Results(orig_img=self.orig_img, path=self.path, names=self.names)\n",
        "    def count_per_class(self):\n",
        "        \"\"\"Count the number of detections per class.\"\"\"\n",
        "        count_dict = {class_name: 0 for class_name in self.names.values()}\n",
        "\n",
        "        if self.boxes is not None:\n",
        "            for box in self.boxes:\n",
        "                class_name = self.names[int(box.cls)]\n",
        "                count_dict[class_name] += 1\n",
        "\n",
        "        return count_dict\n",
        "    def plot(self, conf=True, line_width=None, font_size=None, font='Arial.ttf', pil=False, img=None,\n",
        "         im_gpu=None, kpt_radius=5, kpt_line=True, labels=True, boxes=True, masks=True, probs=True):\n",
        "        \"\"\"\n",
        "        Plots the detection results on an input RGB image. Accepts a numpy array (cv2) or a PIL Image.\n",
        "\n",
        "        Args:\n",
        "            conf (bool): Whether to plot the detection confidence score.\n",
        "            line_width (float, optional): The line width of the bounding boxes. If None, it is scaled to the image size.\n",
        "            font_size (float, optional): The font size of the text. If None, it is scaled to the image size.\n",
        "            font (str): The font to use for the text.\n",
        "            pil (bool): Whether to return the image as a PIL Image.\n",
        "            img (numpy.ndarray): Plot to another image. if not, plot to original image.\n",
        "            im_gpu (torch.Tensor): Normalized image in gpu with shape (1, 3, 640, 640), for faster mask plotting.\n",
        "            kpt_radius (int, optional): Radius of the drawn keypoints. Default is 5.\n",
        "            kpt_line (bool): Whether to draw lines connecting keypoints.\n",
        "            labels (bool): Whether to plot the label of bounding boxes.\n",
        "            boxes (bool): Whether to plot the bounding boxes.\n",
        "            masks (bool): Whether to plot the masks.\n",
        "            probs (bool): Whether to plot classification probability\n",
        "\n",
        "        Returns:\n",
        "            (numpy.ndarray): A numpy array of the annotated image.\n",
        "\n",
        "        Example:\n",
        "            ```python\n",
        "            from PIL import Image\n",
        "            from ultralytics import YOLO\n",
        "\n",
        "            model = YOLO('yolov8n.pt')\n",
        "            results = model('bus.jpg')  # results list\n",
        "            for r in results:\n",
        "                im_array = r.plot()  # plot a BGR numpy array of predictions\n",
        "                im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
        "                im.show()  # show image\n",
        "                im.save('results.jpg')  # save image\n",
        "            ```\n",
        "        \"\"\"\n",
        "        if img is None and isinstance(self.orig_img, torch.Tensor):\n",
        "            img = (self.orig_img[0].detach().permute(1, 2, 0).contiguous() * 255).to(torch.uint8).cpu().numpy()\n",
        "\n",
        "        names = self.names\n",
        "        pred_boxes, show_boxes = self.boxes, boxes\n",
        "        pred_masks, show_masks = self.masks, masks\n",
        "        pred_probs, show_probs = self.probs, probs\n",
        "        annotator = Annotator(\n",
        "            deepcopy(self.orig_img if img is None else img),\n",
        "            line_width,\n",
        "            font_size,\n",
        "            font,\n",
        "            pil or (pred_probs is not None and show_probs),  # Classify tasks default to pil=True\n",
        "            example=names)\n",
        "\n",
        "        # Plot Segment results\n",
        "        if pred_masks and show_masks:\n",
        "            if im_gpu is None:\n",
        "                img = LetterBox(pred_masks.shape[1:])(image=annotator.result())\n",
        "                im_gpu = torch.as_tensor(img, dtype=torch.float16, device=pred_masks.data.device).permute(\n",
        "                    2, 0, 1).flip(0).contiguous() / 255\n",
        "            idx = pred_boxes.cls if pred_boxes else range(len(pred_masks))\n",
        "            annotator.masks(pred_masks.data, colors=[colors(x, True) for x in idx], im_gpu=im_gpu)\n",
        "\n",
        "        # Plot Detect results\n",
        "        if pred_boxes and show_boxes:\n",
        "            count_info = self.count_per_class()\n",
        "            print(count_info)\n",
        "            text_count = \" --- \".join([f'Number of {class_name}: {count_info[class_name]}' for class_name in count_info])\n",
        "            print(text_count)\n",
        "            for d in reversed(pred_boxes):\n",
        "                c, conf, id = int(d.cls), float(d.conf) if conf else None, None if d.id is None else int(d.id.item())\n",
        "                name = ('' if id is None else f'id:{id} ') + names[c]\n",
        "                label = (f'{name} {conf:.2f}' if conf else name) if labels else None\n",
        "                annotator.box_label(d.xyxy.squeeze(), label, color=colors(c, True))\n",
        "            text_position = [10, 100]  # Adjusted position for count information\n",
        "            annotator.text(text_position, text_count, txt_color=(100, 0, 0))\n",
        "\n",
        "        # Plot Classify results\n",
        "        if pred_probs is not None and show_probs:\n",
        "            text = ' --- '.join(f'{names[j] if names else j} {pred_probs.data[j]:.2f}' for j in pred_probs.top5)\n",
        "            x = round(self.orig_shape[0] * 0.03)\n",
        "\n",
        "            annotator.text([x, x], text, txt_color=(255, 255, 255))  # TODO: allow setting colors\n",
        "\n",
        "        # Plot Pose results\n",
        "        if self.keypoints is not None:\n",
        "            for k in reversed(self.keypoints.data):\n",
        "                annotator.kpts(k, self.orig_shape, radius=kpt_radius, kpt_line=kpt_line)\n",
        "\n",
        "        return annotator.result()\n",
        "\n",
        "    def verbose(self):\n",
        "        \"\"\"Return log string for each task.\"\"\"\n",
        "        log_string = ''\n",
        "        probs = self.probs\n",
        "        boxes = self.boxes\n",
        "        if len(self) == 0:\n",
        "            return log_string if probs is not None else f'{log_string}(no detections), '\n",
        "        if probs is not None:\n",
        "            log_string += f\"{', '.join(f'{self.names[j]} {probs.data[j]:.2f}' for j in probs.top5)}, \"\n",
        "        if boxes:\n",
        "            for c in boxes.cls.unique():\n",
        "                n = (boxes.cls == c).sum()  # detections per class\n",
        "                log_string += f\"{n} {self.names[int(c)]}{'s' * (n > 1)}, \"\n",
        "        return log_string\n",
        "\n",
        "    def save_txt(self, txt_file, save_conf=False):\n",
        "        \"\"\"\n",
        "        Save predictions into txt file.\n",
        "\n",
        "        Args:\n",
        "            txt_file (str): txt file path.\n",
        "            save_conf (bool): save confidence score or not.\n",
        "        \"\"\"\n",
        "        boxes = self.boxes\n",
        "        masks = self.masks\n",
        "        probs = self.probs\n",
        "        kpts = self.keypoints\n",
        "        texts = []\n",
        "        if probs is not None:\n",
        "            # Classify\n",
        "            [texts.append(f'{probs.data[j]:.2f} {self.names[j]}') for j in probs.top5]\n",
        "        elif boxes:\n",
        "            # Detect/segment/pose\n",
        "            for j, d in enumerate(boxes):\n",
        "                c, conf, id = int(d.cls), float(d.conf), None if d.id is None else int(d.id.item())\n",
        "                line = (c, *d.xywhn.view(-1))\n",
        "                if masks:\n",
        "                    seg = masks[j].xyn[0].copy().reshape(-1)  # reversed mask.xyn, (n,2) to (n*2)\n",
        "                    line = (c, *seg)\n",
        "                if kpts is not None:\n",
        "                    kpt = torch.cat((kpts[j].xyn, kpts[j].conf[..., None]), 2) if kpts[j].has_visible else kpts[j].xyn\n",
        "                    line += (*kpt.reshape(-1).tolist(), )\n",
        "                line += (conf, ) * save_conf + (() if id is None else (id, ))\n",
        "                texts.append(('%g ' * len(line)).rstrip() % line)\n",
        "\n",
        "        if texts:\n",
        "            Path(txt_file).parent.mkdir(parents=True, exist_ok=True)  # make directory\n",
        "            with open(txt_file, 'a') as f:\n",
        "                f.writelines(text + '\\n' for text in texts)\n",
        "\n",
        "    def save_crop(self, save_dir, file_name=Path('im.jpg')):\n",
        "        \"\"\"\n",
        "        Save cropped predictions to `save_dir/cls/file_name.jpg`.\n",
        "\n",
        "        Args:\n",
        "            save_dir (str | pathlib.Path): Save path.\n",
        "            file_name (str | pathlib.Path): File name.\n",
        "        \"\"\"\n",
        "        if self.probs is not None:\n",
        "            LOGGER.warning('WARNING âš ï¸ Classify task do not support `save_crop`.')\n",
        "            return\n",
        "        for d in self.boxes:\n",
        "            save_one_box(d.xyxy,\n",
        "                         self.orig_img.copy(),\n",
        "                         file=Path(save_dir) / self.names[int(d.cls)] / f'{Path(file_name).stem}.jpg',\n",
        "                         BGR=True)\n",
        "\n",
        "    def tojson(self, normalize=False):\n",
        "        \"\"\"Convert the object to JSON format.\"\"\"\n",
        "        if self.probs is not None:\n",
        "            LOGGER.warning('Warning: Classify task do not support `tojson` yet.')\n",
        "            return\n",
        "\n",
        "        import json\n",
        "\n",
        "        # Create list of detection dictionaries\n",
        "        results = []\n",
        "        data = self.boxes.data.cpu().tolist()\n",
        "        h, w = self.orig_shape if normalize else (1, 1)\n",
        "        for i, row in enumerate(data):  # xyxy, track_id if tracking, conf, class_id\n",
        "            box = {'x1': row[0] / w, 'y1': row[1] / h, 'x2': row[2] / w, 'y2': row[3] / h}\n",
        "            conf = row[-2]\n",
        "            class_id = int(row[-1])\n",
        "            name = self.names[class_id]\n",
        "            result = {'name': name, 'class': class_id, 'confidence': conf, 'box': box}\n",
        "            if self.boxes.is_track:\n",
        "                result['track_id'] = int(row[-3])  # track ID\n",
        "            if self.masks:\n",
        "                x, y = self.masks.xy[i][:, 0], self.masks.xy[i][:, 1]  # numpy array\n",
        "                result['segments'] = {'x': (x / w).tolist(), 'y': (y / h).tolist()}\n",
        "            if self.keypoints is not None:\n",
        "                x, y, visible = self.keypoints[i].data[0].cpu().unbind(dim=1)  # torch Tensor\n",
        "                result['keypoints'] = {'x': (x / w).tolist(), 'y': (y / h).tolist(), 'visible': visible.tolist()}\n",
        "            results.append(result)\n",
        "\n",
        "        # Convert detections to JSON\n",
        "        return json.dumps(results, indent=2)\n",
        "\n",
        "\n",
        "class Boxes(BaseTensor):\n",
        "    \"\"\"\n",
        "    A class for storing and manipulating detection boxes.\n",
        "\n",
        "    Args:\n",
        "        boxes (torch.Tensor | numpy.ndarray): A tensor or numpy array containing the detection boxes,\n",
        "            with shape (num_boxes, 6) or (num_boxes, 7). The last two columns contain confidence and class values.\n",
        "            If present, the third last column contains track IDs.\n",
        "        orig_shape (tuple): Original image size, in the format (height, width).\n",
        "\n",
        "    Attributes:\n",
        "        xyxy (torch.Tensor | numpy.ndarray): The boxes in xyxy format.\n",
        "        conf (torch.Tensor | numpy.ndarray): The confidence values of the boxes.\n",
        "        cls (torch.Tensor | numpy.ndarray): The class values of the boxes.\n",
        "        id (torch.Tensor | numpy.ndarray): The track IDs of the boxes (if available).\n",
        "        xywh (torch.Tensor | numpy.ndarray): The boxes in xywh format.\n",
        "        xyxyn (torch.Tensor | numpy.ndarray): The boxes in xyxy format normalized by original image size.\n",
        "        xywhn (torch.Tensor | numpy.ndarray): The boxes in xywh format normalized by original image size.\n",
        "        data (torch.Tensor): The raw bboxes tensor (alias for `boxes`).\n",
        "\n",
        "    Methods:\n",
        "        cpu(): Move the object to CPU memory.\n",
        "        numpy(): Convert the object to a numpy array.\n",
        "        cuda(): Move the object to CUDA memory.\n",
        "        to(*args, **kwargs): Move the object to the specified device.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, boxes, orig_shape) -> None:\n",
        "        \"\"\"Initialize the Boxes class.\"\"\"\n",
        "        if boxes.ndim == 1:\n",
        "            boxes = boxes[None, :]\n",
        "        n = boxes.shape[-1]\n",
        "        assert n in (6, 7), f'expected `n` in [6, 7], but got {n}'  # xyxy, track_id, conf, cls\n",
        "        super().__init__(boxes, orig_shape)\n",
        "        self.is_track = n == 7\n",
        "        self.orig_shape = orig_shape\n",
        "\n",
        "    @property\n",
        "    def xyxy(self):\n",
        "        \"\"\"Return the boxes in xyxy format.\"\"\"\n",
        "        return self.data[:, :4]\n",
        "\n",
        "    @property\n",
        "    def conf(self):\n",
        "        \"\"\"Return the confidence values of the boxes.\"\"\"\n",
        "        return self.data[:, -2]\n",
        "\n",
        "    @property\n",
        "    def cls(self):\n",
        "        \"\"\"Return the class values of the boxes.\"\"\"\n",
        "        return self.data[:, -1]\n",
        "\n",
        "    @property\n",
        "    def id(self):\n",
        "        \"\"\"Return the track IDs of the boxes (if available).\"\"\"\n",
        "        return self.data[:, -3] if self.is_track else None\n",
        "\n",
        "    @property\n",
        "    @lru_cache(maxsize=2)  # maxsize 1 should suffice\n",
        "    def xywh(self):\n",
        "        \"\"\"Return the boxes in xywh format.\"\"\"\n",
        "        return ops.xyxy2xywh(self.xyxy)\n",
        "\n",
        "    @property\n",
        "    @lru_cache(maxsize=2)\n",
        "    def xyxyn(self):\n",
        "        \"\"\"Return the boxes in xyxy format normalized by original image size.\"\"\"\n",
        "        xyxy = self.xyxy.clone() if isinstance(self.xyxy, torch.Tensor) else np.copy(self.xyxy)\n",
        "        xyxy[..., [0, 2]] /= self.orig_shape[1]\n",
        "        xyxy[..., [1, 3]] /= self.orig_shape[0]\n",
        "        return xyxy\n",
        "\n",
        "    @property\n",
        "    @lru_cache(maxsize=2)\n",
        "    def xywhn(self):\n",
        "        \"\"\"Return the boxes in xywh format normalized by original image size.\"\"\"\n",
        "        xywh = ops.xyxy2xywh(self.xyxy)\n",
        "        xywh[..., [0, 2]] /= self.orig_shape[1]\n",
        "        xywh[..., [1, 3]] /= self.orig_shape[0]\n",
        "        return xywh\n",
        "\n",
        "\n",
        "class Masks(BaseTensor):\n",
        "    \"\"\"\n",
        "    A class for storing and manipulating detection masks.\n",
        "\n",
        "    Attributes:\n",
        "        xy (list): A list of segments in pixel coordinates.\n",
        "        xyn (list): A list of normalized segments.\n",
        "\n",
        "    Methods:\n",
        "        cpu(): Returns the masks tensor on CPU memory.\n",
        "        numpy(): Returns the masks tensor as a numpy array.\n",
        "        cuda(): Returns the masks tensor on GPU memory.\n",
        "        to(device, dtype): Returns the masks tensor with the specified device and dtype.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, masks, orig_shape) -> None:\n",
        "        \"\"\"Initialize the Masks class with the given masks tensor and original image shape.\"\"\"\n",
        "        if masks.ndim == 2:\n",
        "            masks = masks[None, :]\n",
        "        super().__init__(masks, orig_shape)\n",
        "\n",
        "    @property\n",
        "    @lru_cache(maxsize=1)\n",
        "    def xyn(self):\n",
        "        \"\"\"Return normalized segments.\"\"\"\n",
        "        return [\n",
        "            ops.scale_coords(self.data.shape[1:], x, self.orig_shape, normalize=True)\n",
        "            for x in ops.masks2segments(self.data)]\n",
        "\n",
        "    @property\n",
        "    @lru_cache(maxsize=1)\n",
        "    def xy(self):\n",
        "        \"\"\"Return segments in pixel coordinates.\"\"\"\n",
        "        return [\n",
        "            ops.scale_coords(self.data.shape[1:], x, self.orig_shape, normalize=False)\n",
        "            for x in ops.masks2segments(self.data)]\n",
        "\n",
        "\n",
        "class Keypoints(BaseTensor):\n",
        "    \"\"\"\n",
        "    A class for storing and manipulating detection keypoints.\n",
        "\n",
        "    Attributes:\n",
        "        xy (torch.Tensor): A collection of keypoints containing x, y coordinates for each detection.\n",
        "        xyn (torch.Tensor): A normalized version of xy with coordinates in the range [0, 1].\n",
        "        conf (torch.Tensor): Confidence values associated with keypoints if available, otherwise None.\n",
        "\n",
        "    Methods:\n",
        "        cpu(): Returns a copy of the keypoints tensor on CPU memory.\n",
        "        numpy(): Returns a copy of the keypoints tensor as a numpy array.\n",
        "        cuda(): Returns a copy of the keypoints tensor on GPU memory.\n",
        "        to(device, dtype): Returns a copy of the keypoints tensor with the specified device and dtype.\n",
        "    \"\"\"\n",
        "\n",
        "    @smart_inference_mode()  # avoid keypoints < conf in-place error\n",
        "    def __init__(self, keypoints, orig_shape) -> None:\n",
        "        \"\"\"Initializes the Keypoints object with detection keypoints and original image size.\"\"\"\n",
        "        if keypoints.ndim == 2:\n",
        "            keypoints = keypoints[None, :]\n",
        "        if keypoints.shape[2] == 3:  # x, y, conf\n",
        "            mask = keypoints[..., 2] < 0.5  # points with conf < 0.5 (not visible)\n",
        "            keypoints[..., :2][mask] = 0\n",
        "        super().__init__(keypoints, orig_shape)\n",
        "        self.has_visible = self.data.shape[-1] == 3\n",
        "\n",
        "    @property\n",
        "    @lru_cache(maxsize=1)\n",
        "    def xy(self):\n",
        "        \"\"\"Returns x, y coordinates of keypoints.\"\"\"\n",
        "        return self.data[..., :2]\n",
        "\n",
        "    @property\n",
        "    @lru_cache(maxsize=1)\n",
        "    def xyn(self):\n",
        "        \"\"\"Returns normalized x, y coordinates of keypoints.\"\"\"\n",
        "        xy = self.xy.clone() if isinstance(self.xy, torch.Tensor) else np.copy(self.xy)\n",
        "        xy[..., 0] /= self.orig_shape[1]\n",
        "        xy[..., 1] /= self.orig_shape[0]\n",
        "        return xy\n",
        "\n",
        "    @property\n",
        "    @lru_cache(maxsize=1)\n",
        "    def conf(self):\n",
        "        \"\"\"Returns confidence values of keypoints if available, else None.\"\"\"\n",
        "        return self.data[..., 2] if self.has_visible else None\n",
        "\n",
        "\n",
        "class Probs(BaseTensor):\n",
        "    \"\"\"\n",
        "    A class for storing and manipulating classification predictions.\n",
        "\n",
        "    Attributes:\n",
        "        top1 (int): Index of the top 1 class.\n",
        "        top5 (list[int]): Indices of the top 5 classes.\n",
        "        top1conf (torch.Tensor): Confidence of the top 1 class.\n",
        "        top5conf (torch.Tensor): Confidences of the top 5 classes.\n",
        "\n",
        "    Methods:\n",
        "        cpu(): Returns a copy of the probs tensor on CPU memory.\n",
        "        numpy(): Returns a copy of the probs tensor as a numpy array.\n",
        "        cuda(): Returns a copy of the probs tensor on GPU memory.\n",
        "        to(): Returns a copy of the probs tensor with the specified device and dtype.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, probs, orig_shape=None) -> None:\n",
        "        \"\"\"Initialize the Probs class with classification probabilities and optional original shape of the image.\"\"\"\n",
        "        super().__init__(probs, orig_shape)\n",
        "\n",
        "    @property\n",
        "    @lru_cache(maxsize=1)\n",
        "    def top1(self):\n",
        "        \"\"\"Return the index of top 1.\"\"\"\n",
        "        return int(self.data.argmax())\n",
        "\n",
        "    @property\n",
        "    @lru_cache(maxsize=1)\n",
        "    def top5(self):\n",
        "        \"\"\"Return the indices of top 5.\"\"\"\n",
        "        return (-self.data).argsort(0)[:5].tolist()  # this way works with both torch and numpy.\n",
        "\n",
        "    @property\n",
        "    @lru_cache(maxsize=1)\n",
        "    def top1conf(self):\n",
        "        \"\"\"Return the confidence of top 1.\"\"\"\n",
        "        return self.data[self.top1]\n",
        "\n",
        "    @property\n",
        "    @lru_cache(maxsize=1)\n",
        "    def top5conf(self):\n",
        "        \"\"\"Return the confidences of top 5.\"\"\"\n",
        "        return self.data[self.top5]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=train model=/content/car_detectionv2.pt data=/content/ultralytics/CarBus-3/data.yaml epochs=100 imgsz=640 plots=True"
      ],
      "metadata": {
        "id": "Ynd2fpQ1U9cG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"W6D3zFpw6pKUK31pvev4\")\n",
        "project = rf.workspace(\"vnu-ehycy\").project(\"carbus-zrvi1\")\n",
        "dataset = project.version(4).download(\"yolov5\")\n"
      ],
      "metadata": {
        "id": "znyEueRt1D-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=train model=/content/ultralytics/runs/detect/train4/weights/best.pt data=/content/ultralytics/CarBus-4/data.yaml epochs=100 imgsz=640 plots=True"
      ],
      "metadata": {
        "id": "vFCj7NkN03DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/ultralytics/runs/detect/train2/weights"
      ],
      "metadata": {
        "id": "Xgt4pEZlUUAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r res.zip /content/ultralytics/runs/detect/train2"
      ],
      "metadata": {
        "id": "CcI1wpNVUZKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wjc1ctZykYuf"
      },
      "outputs": [],
      "source": [
        "!yolo task=detect mode=predict model=/content/ultralytics/car_detection.pt conf=0.25 source=/content/test.jpg save=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEYIo95n-I0S"
      },
      "source": [
        "**NOTE:** Let's take a look at few results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puuyx-DgUVRj"
      },
      "outputs": [],
      "source": [
        "%cd /content/ultralytics\n",
        "\n",
        "!yolo task=detect mode=train model=/content/car_detection.pt data=/content/car-3/data.yaml epochs=100 imgsz=640 plots=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbVjEtPAkz3j"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for image_path in glob.glob(f'/content/ultralytics/runs/detect/predict/*.jpg')[:3]:\n",
        "      display(Image(filename=image_path, width=600))\n",
        "      print(\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}